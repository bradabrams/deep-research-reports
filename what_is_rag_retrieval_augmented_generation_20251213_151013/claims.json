{
  "claims": [
    {
      "id": "origin-001",
      "category": "historical",
      "claim": "RAG was first introduced in a 2020 research paper by Patrick Lewis and colleagues from Meta AI, UCL, and NYU",
      "confidence": "HIGH",
      "sources": ["meta-ai-2020", "arxiv-2005.11401", "nvidia-rag"],
      "verification_notes": "Multiple authoritative sources confirm",
      "verified": true
    },
    {
      "id": "market-001",
      "category": "market",
      "claim": "Global RAG market valued at $1.2-1.9B in 2024, projected to reach $9.86-11B by 2030",
      "confidence": "HIGH",
      "sources": ["grandview-market", "marketsandmarkets-rag"],
      "verified": true
    },
    {
      "id": "growth-001",
      "category": "market",
      "claim": "RAG research grew from 10 papers (2022) to 93 (2023) to 1,202 (2024)",
      "confidence": "MEDIUM",
      "sources": ["ragflow-2024-review"],
      "verified": true
    },
    {
      "id": "hallucination-001",
      "category": "technical",
      "claim": "RAG reduces hallucinations by 42-68% compared to baseline LLMs",
      "confidence": "MEDIUM",
      "sources": ["vectara-hallucinations"],
      "verification_notes": "Disputed by some - RAG reduces but does not eliminate hallucinations",
      "verified": true
    },
    {
      "id": "hallucination-002",
      "category": "technical",
      "claim": "RAG + RLHF + guardrails achieves up to 96% hallucination reduction",
      "confidence": "HIGH",
      "sources": ["stanford-legal-rag"],
      "verified": true
    },
    {
      "id": "failure-001",
      "category": "critical",
      "claim": "Up to 70% of RAG systems fail in production",
      "confidence": "LOW",
      "sources": ["ai-accelerator-institute"],
      "verification_notes": "Single source, potentially sensationalized",
      "verified": true
    },
    {
      "id": "failure-002",
      "category": "critical",
      "claim": "Seven failure points in RAG: missing content, missed documents, not in context, not extracted, wrong format, incorrect specificity, incomplete responses",
      "confidence": "HIGH",
      "sources": ["arxiv-seven-failures"],
      "verified": true
    },
    {
      "id": "chunking-001",
      "category": "technical",
      "claim": "Recommended chunk size: 400-512 tokens with 10-20% overlap",
      "confidence": "HIGH",
      "sources": ["weaviate-chunking", "stackoverflow-chunking", "chroma-chunking-research"],
      "verified": true
    },
    {
      "id": "chunking-002",
      "category": "technical",
      "claim": "Wrong chunking strategy creates up to 9% gap in recall performance",
      "confidence": "HIGH",
      "sources": ["chroma-chunking-research"],
      "verified": true
    },
    {
      "id": "graphrag-001",
      "category": "technical",
      "claim": "GraphRAG (Microsoft 2024) outperforms baseline RAG for complex reasoning and multi-hop queries",
      "confidence": "HIGH",
      "sources": ["microsoft-graphrag", "ibm-graphrag"],
      "verified": true
    },
    {
      "id": "longcontext-001",
      "category": "comparison",
      "claim": "Long-context LLMs can outperform RAG in benchmarks but RAG remains advantageous for dynamic data and cost",
      "confidence": "HIGH",
      "sources": ["arxiv-longcontext-rag", "databricks-longcontext"],
      "verified": true
    },
    {
      "id": "hallucination-persist",
      "category": "critical",
      "claim": "RAG can still hallucinate even with accurate retrieval due to LLM internal mechanisms",
      "confidence": "HIGH",
      "sources": ["arxiv-redeep", "mdpi-hallucination-review"],
      "verified": true
    },
    {
      "id": "enterprise-001",
      "category": "market",
      "claim": "Large enterprises account for 72.2% of RAG market share",
      "confidence": "MEDIUM",
      "sources": ["grandview-market"],
      "verified": true
    },
    {
      "id": "usecase-linkedin",
      "category": "use-case",
      "claim": "LinkedIn RAG + knowledge graph reduced issue resolution time by 28.6%",
      "confidence": "HIGH",
      "sources": ["evidentlyai-rag-examples"],
      "verified": true
    },
    {
      "id": "agentic-001",
      "category": "technical",
      "claim": "Agentic RAG embeds autonomous agents with planning, reflection, and tool use capabilities",
      "confidence": "HIGH",
      "sources": ["arxiv-agentic-rag"],
      "verified": true
    },
    {
      "id": "comparison-001",
      "category": "comparison",
      "claim": "RAG doesn't modify LLM weights; enables knowledge updates without retraining",
      "confidence": "HIGH",
      "sources": ["ibm-rag-vs-finetuning", "redhat-rag-vs-finetuning"],
      "verified": true
    }
  ],
  "metadata": {
    "topic": "RAG (Retrieval Augmented Generation)",
    "created": "2025-12-13",
    "updated": "2025-12-13",
    "verification_completed": true,
    "total_claims": 16,
    "confidence_breakdown": {
      "HIGH": 11,
      "MEDIUM": 4,
      "LOW": 1
    }
  }
}
