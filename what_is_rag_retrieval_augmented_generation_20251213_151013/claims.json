{
  "claims": [
    {
      "id": "origin-001",
      "category": "historical",
      "claim": "RAG was first introduced in a 2020 research paper by Patrick Lewis and colleagues from Meta AI (Facebook AI Research), University College London, and New York University",
      "confidence": "HIGH",
      "sources": ["meta-ai-2020", "arxiv-2005.11401", "nvidia-rag"],
      "verification_notes": "Multiple authoritative sources confirm the 2020 origin and authors"
    },
    {
      "id": "origin-002",
      "category": "historical",
      "claim": "The original RAG paper was submitted to arXiv on May 22, 2020, and presented at NeurIPS 2020",
      "confidence": "HIGH",
      "sources": ["arxiv-2005.11401", "nvidia-rag"],
      "verification_notes": "Confirmed via arXiv submission date"
    },
    {
      "id": "growth-001",
      "category": "market",
      "claim": "RAG research grew explosively from 10 papers in 2022 to 93 in 2023 to 1,202 papers in 2024",
      "confidence": "MEDIUM",
      "sources": ["ragflow-2024-review"],
      "verification_notes": "Single source (RAGFlow), based on arXiv search"
    },
    {
      "id": "market-001",
      "category": "market",
      "claim": "The global RAG market was valued at approximately $1.2-1.9 billion in 2024",
      "confidence": "HIGH",
      "sources": ["grandview-market", "marketsandmarkets-rag"],
      "verification_notes": "Grand View: $1.2B, MarketsandMarkets: $1.94B - range reflects different methodologies"
    },
    {
      "id": "market-002",
      "category": "market",
      "claim": "RAG market is projected to reach $9.86-11 billion by 2030, with CAGR of 38-49%",
      "confidence": "HIGH",
      "sources": ["grandview-market", "marketsandmarkets-rag"],
      "verification_notes": "Multiple analyst firms with slightly different projections"
    },
    {
      "id": "market-003",
      "category": "market",
      "claim": "Large enterprises account for 72.2% of RAG market share (2024)",
      "confidence": "MEDIUM",
      "sources": ["grandview-market"],
      "verification_notes": "Single analyst source"
    },
    {
      "id": "market-004",
      "category": "market",
      "claim": "Enterprises use RAG for 30-60% of their GenAI use cases",
      "confidence": "MEDIUM",
      "sources": ["vectara-predictions-2025"],
      "verification_notes": "Single vendor source"
    },
    {
      "id": "market-005",
      "category": "market",
      "claim": "Vector database market valued at ~$2.2B in 2024, projected to reach $10.6B by 2032 (21% CAGR)",
      "confidence": "MEDIUM",
      "sources": ["liquidmetal-vectordb"],
      "verification_notes": "Secondary source citing market analysts"
    },
    {
      "id": "hallucination-001",
      "category": "technical",
      "claim": "RAG reduces hallucinations by 42-68% compared to baseline LLMs",
      "confidence": "MEDIUM",
      "sources": ["vectara-hallucinations"],
      "verification_notes": "Research cited but single source"
    },
    {
      "id": "hallucination-002",
      "category": "technical",
      "claim": "Combining RAG, RLHF, and guardrails led to 96% reduction in hallucinations (Stanford 2024 study)",
      "confidence": "HIGH",
      "sources": ["stanford-legal-rag"],
      "verification_notes": "Peer-reviewed academic study"
    },
    {
      "id": "hallucination-003",
      "category": "technical",
      "claim": "RAGTruth hallucination detectors reduced hallucination rates by 21.8-56.6% for smaller models (Llama-2-7B, Mistral-7B)",
      "confidence": "HIGH",
      "sources": ["arxiv-ragtruth"],
      "verification_notes": "Peer-reviewed academic research"
    },
    {
      "id": "hallucination-004",
      "category": "technical",
      "claim": "For GPT-3.5-Turbo and GPT-4, hallucination detection reduced rates by 41% and 52.9% respectively",
      "confidence": "HIGH",
      "sources": ["arxiv-ragtruth"],
      "verification_notes": "Peer-reviewed academic research"
    },
    {
      "id": "legal-001",
      "category": "use-case",
      "claim": "LexisNexis Lexis+ AI achieved 65% accuracy in legal queries, Westlaw AI 42% accuracy but hallucinated nearly twice as often as other legal tools",
      "confidence": "HIGH",
      "sources": ["stanford-legal-rag"],
      "verification_notes": "Stanford peer-reviewed study (2025)"
    },
    {
      "id": "chunking-001",
      "category": "technical",
      "claim": "Recommended chunk size: 400-512 tokens with 10-20% overlap as baseline",
      "confidence": "HIGH",
      "sources": ["weaviate-chunking", "stackoverflow-chunking", "chroma-chunking-research"],
      "verification_notes": "Multiple sources agree on this recommendation"
    },
    {
      "id": "chunking-002",
      "category": "technical",
      "claim": "NVIDIA 2024 benchmark: Page-level chunking achieved 0.648 accuracy with lowest standard deviation (0.107)",
      "confidence": "MEDIUM",
      "sources": ["stackoverflow-chunking"],
      "verification_notes": "NVIDIA benchmark cited in secondary source"
    },
    {
      "id": "chunking-003",
      "category": "technical",
      "claim": "Wrong chunking strategy creates up to 9% gap in recall performance between best and worst approaches",
      "confidence": "HIGH",
      "sources": ["chroma-chunking-research"],
      "verification_notes": "Primary research from Chroma"
    },
    {
      "id": "chunking-004",
      "category": "technical",
      "claim": "ClusterSemanticChunker at 200-token max achieved highest precision (8.0) and IoU (8.0) in Chroma benchmarks",
      "confidence": "HIGH",
      "sources": ["chroma-chunking-research"],
      "verification_notes": "Primary research with reproducible benchmarks"
    },
    {
      "id": "graphrag-001",
      "category": "technical",
      "claim": "GraphRAG introduced by Microsoft Research in 2024 to address baseline RAG limitations with knowledge graphs",
      "confidence": "HIGH",
      "sources": ["microsoft-graphrag", "microsoft-graphrag-docs", "ibm-graphrag"],
      "verification_notes": "Multiple authoritative sources confirm"
    },
    {
      "id": "graphrag-002",
      "category": "technical",
      "claim": "GraphRAG outperforms baseline RAG for complex reasoning, holistic queries, and multi-hop questions",
      "confidence": "HIGH",
      "sources": ["microsoft-graphrag", "ibm-graphrag"],
      "verification_notes": "Microsoft Research evaluation confirms"
    },
    {
      "id": "graphrag-003",
      "category": "technical",
      "claim": "Baseline RAG fails at aggregation queries like 'What are the top 5 themes in the data?' while GraphRAG succeeds",
      "confidence": "HIGH",
      "sources": ["microsoft-graphrag"],
      "verification_notes": "Specific example from Microsoft Research"
    },
    {
      "id": "agentic-001",
      "category": "technical",
      "claim": "Agentic RAG embeds autonomous agents with reflection, planning, tool use, and multi-agent collaboration capabilities",
      "confidence": "HIGH",
      "sources": ["arxiv-agentic-rag"],
      "verification_notes": "Academic survey paper (January 2025)"
    },
    {
      "id": "agentic-002",
      "category": "market",
      "claim": "33% of enterprise software expected to include agentic AI by 2028, up from under 1% in 2024",
      "confidence": "MEDIUM",
      "sources": ["arxiv-agentic-rag"],
      "verification_notes": "Projection cited in academic paper"
    },
    {
      "id": "vectordb-001",
      "category": "technical",
      "claim": "Milvus leads in queries per second and supports 11 different index types",
      "confidence": "MEDIUM",
      "sources": ["liquidmetal-vectordb", "qdrant-benchmarks"],
      "verification_notes": "Benchmark data may vary by configuration"
    },
    {
      "id": "vectordb-002",
      "category": "technical",
      "claim": "Pinecone and Milvus both offer sub-2ms latency for vector searches",
      "confidence": "MEDIUM",
      "sources": ["liquidmetal-vectordb"],
      "verification_notes": "Benchmark dependent on specific configurations"
    },
    {
      "id": "usecase-001",
      "category": "use-case",
      "claim": "DoorDash uses RAG-based chatbot for delivery support, combining RAG with LLM guardrails and judges",
      "confidence": "HIGH",
      "sources": ["evidentlyai-rag-examples"],
      "verification_notes": "Company case study cited"
    },
    {
      "id": "usecase-002",
      "category": "use-case",
      "claim": "LinkedIn's RAG + knowledge graph approach reduced median issue resolution time by 28.6%",
      "confidence": "HIGH",
      "sources": ["evidentlyai-rag-examples"],
      "verification_notes": "Specific metric from company implementation"
    },
    {
      "id": "usecase-003",
      "category": "use-case",
      "claim": "Siemens uses RAG for internal knowledge management across documents and databases",
      "confidence": "MEDIUM",
      "sources": ["evidentlyai-rag-examples"],
      "verification_notes": "Company case study cited"
    },
    {
      "id": "multimodal-001",
      "category": "technical",
      "claim": "Multimodal RAG expands traditional RAG to incorporate text, images, tables, audio, and video files",
      "confidence": "HIGH",
      "sources": ["ibm-multimodal-rag", "nvidia-multimodal-rag"],
      "verification_notes": "Multiple authoritative sources agree"
    },
    {
      "id": "multimodal-002",
      "category": "market",
      "claim": "Multimodal RAG survey accepted for ACL 2025 Findings publication",
      "confidence": "HIGH",
      "sources": ["nvidia-multimodal-rag"],
      "verification_notes": "Academic acceptance confirmed"
    },
    {
      "id": "architecture-001",
      "category": "technical",
      "claim": "RAG architecture has two main phases: Build Time (indexing/embedding) and Runtime (query/retrieval/generation)",
      "confidence": "HIGH",
      "sources": ["ibm-architecture-rag", "azure-rag-architecture", "aws-rag"],
      "verification_notes": "Fundamental architecture confirmed by multiple cloud providers"
    },
    {
      "id": "architecture-002",
      "category": "technical",
      "claim": "Core RAG components: document preprocessing, embedding model, vector database, retrieval engine, LLM, response post-processor",
      "confidence": "HIGH",
      "sources": ["ibm-architecture-rag", "azure-rag-architecture"],
      "verification_notes": "Consistent across multiple architectural guides"
    },
    {
      "id": "comparison-001",
      "category": "comparison",
      "claim": "RAG doesn't modify LLM weights; fine-tuning adjusts weights and parameters",
      "confidence": "HIGH",
      "sources": ["ibm-rag-vs-finetuning", "redhat-rag-vs-finetuning"],
      "verification_notes": "Fundamental distinction confirmed by multiple sources"
    },
    {
      "id": "comparison-002",
      "category": "comparison",
      "claim": "RAG enables knowledge updates without retraining; fine-tuning requires periodic retraining",
      "confidence": "HIGH",
      "sources": ["ibm-rag-vs-finetuning", "redhat-rag-vs-finetuning"],
      "verification_notes": "Key advantage confirmed by multiple sources"
    },
    {
      "id": "comparison-003",
      "category": "comparison",
      "claim": "Fine-tuned models have faster inference (no retrieval step); RAG adds latency for retrieval",
      "confidence": "HIGH",
      "sources": ["ibm-rag-vs-finetuning", "redhat-rag-vs-finetuning"],
      "verification_notes": "Trade-off confirmed by multiple sources"
    }
  ],
  "metadata": {
    "topic": "RAG (Retrieval Augmented Generation)",
    "created": "2025-12-13",
    "total_claims": 34,
    "confidence_breakdown": {
      "HIGH": 24,
      "MEDIUM": 10,
      "LOW": 0,
      "DISPUTED": 0
    },
    "categories": ["historical", "market", "technical", "use-case", "comparison"]
  }
}
